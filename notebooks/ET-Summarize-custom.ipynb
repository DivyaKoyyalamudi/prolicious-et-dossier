{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-identity\n",
    "%pip install langchain===0.0.200\n",
    "%pip install openai, tiktoken\n",
    "%pip install pypdf\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up Langchain for Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os,openai\n",
    "from dotenv import load_dotenv\n",
    "# Load environment variables from a .env file using load_dotenv():\n",
    "load_dotenv()\n",
    "\n",
    "azure_openai_api_key: str = os.environ.get('AZURE_OPENAI_API_KEY')\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"https://verx-corp-ai.openai.azure.com/\"\n",
    "openai.api_version = \"2023-03-15-preview\"\n",
    "openai.api_key = azure_openai_api_key\n",
    "openai.openai_api_key = azure_openai_api_key\n",
    "deployment_id: str = \"VERX-CORP-DAVINCI\"\n",
    "model: str = \"text-davinci-003\"\n",
    "\n",
    "from langchain import OpenAI, PromptTemplate, LLMChain\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = OpenAI(temperature=0, model=model, openai_api_key=azure_openai_api_key, deployment_id=deployment_id)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Text Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting chunky with it (txt)\n",
    "Use this one for parsing a txt document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text document split\n",
    "with open('state_of_union.txt') as f:\n",
    "    state_of_union = f.read()\n",
    "docs = text_splitter.create_documents([state_of_union])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting chunky with it (pdf)\n",
    "Use this one for parsing a pdf document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"../data/Emerging_Tech_Generative AI Code Assistants Are Becoming Essential to Developer Experience_790320_ndx.pdf\")\n",
    "docs = loader.load_and_split()\n",
    "docs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarizing w/Map Reduce"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create the prompts (The Map prompt is used for every chunk, the combine prompt is used to summarize all the summararies.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "import textwrap\n",
    "\n",
    "#customize the prompt\n",
    "\n",
    "map_prompt_template =  \"\"\"You are a research analyst. I will provide you with a section of a document and you will create a summary from it. You will preserve as many details as possible. You will maintain context across the summary. Your section will be combined with the other sections to create summary of the entire document.\n",
    "\n",
    "Your summary must be no longer than 650 characters long.\n",
    "\n",
    "Input: {text} \"\"\"\n",
    "\n",
    "combine_prompt_template = \"\"\"You are a copy editor. Combine the below summaries. The combined output must be less than 4,000 characters long. You must keep the content and context preserved. \n",
    "\n",
    "Input: {text} \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the prompts and perform the summaries.  (if you want to see more detail add verbose=True as a param to load_summarize_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "map_prompt = PromptTemplate(template=map_prompt_template, input_variables=[\"text\"])\n",
    "combine_prompt = PromptTemplate(template=combine_prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "chain = load_summarize_chain(llm, chain_type='map_reduce', map_prompt=map_prompt, combine_prompt=combine_prompt, verbose=True)\n",
    "\n",
    "output_summary = chain.run(docs)\n",
    "wrapped_text = textwrap.fill(output_summary, width=80)\n",
    "print(wrapped_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
