{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF -> Embeddings -> Azure "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Azure Cognitive Search SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --index-url=https://pkgs.dev.azure.com/azure-sdk/public/_packaging/azure-sdk-for-python/pypi/simple/ azure-search-documents==11.4.0a20230509004\n",
    "%pip install azure-identity\n",
    "%pip install langchain===0.0.200\n",
    "%pip install openai, tiktoken\n",
    "%pip install pypdf\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.schema import BaseRetriever\n",
    "from langchain.vectorstores.azuresearch import AzureSearch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure OpenAI settings\n",
    "Configure the OpenAI settings to use Azure OpenAI or OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from a .env file using load_dotenv():\n",
    "load_dotenv()\n",
    "\n",
    "azure_openai_api_key: str = os.environ.get('AZURE_OPENAI_API_KEY')\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"https://verx-corp-ai.openai.azure.com/\"\n",
    "openai.api_version = \"2023-03-15-preview\"\n",
    "openai.api_key = azure_openai_api_key\n",
    "openai.openai_api_key = azure_openai_api_key\n",
    "model: str = \"text-embedding-ada-002\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure vector store settings\n",
    " \n",
    "Set up the vector store settings using environment variables:\n",
    "Change the index name to be your index...  the index name here will also be used for the similarity search below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_address: str = 'https://violet-vector.search.windows.net'\n",
    "vector_store_password: str = os.environ.get('AZURE_VECTOR_STORE_PASSWORD')\n",
    "index_name: str = \"et-docs-html\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embeddings and vector store instances\n",
    " \n",
    "Create instances of the OpenAIEmbeddings and AzureSearch classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings: OpenAIEmbeddings = OpenAIEmbeddings(model=model, chunk_size=1, openai_api_key=azure_openai_api_key, deployment='VERX-CORP-ADA-002')  \n",
    "vector_store: AzureSearch = AzureSearch(azure_search_endpoint=vector_store_address,  \n",
    "                                        azure_search_key=vector_store_password,  \n",
    "                                        index_name=index_name,  \n",
    "                                        embedding_function=embeddings.embed_query)  \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF to Text and embeddings into vector store"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "loader = PyPDFDirectoryLoader(\"../data/\")\n",
    "docs = loader.load()\n",
    "len(docs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=0)\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "len(split_docs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.add_documents(documents=split_docs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert text and embeddings into vector store\n",
    " \n",
    "Add texts and metadata from the JSON data to the vector store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "loader = TextLoader('../data/mobydick.txt', encoding='utf-8')\n",
    "\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "vector_store.add_documents(documents=docs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URL \n",
    "This covers ow to load HTML documents from a list of URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader([\"https://www.espn.com/\", \"https://www.google.com\"])\n",
    "html_data = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=0)\n",
    "split_docs = text_splitter.split_documents(html_data)\n",
    "len(split_docs)\n",
    "vector_store.add_documents(documents=split_docs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a vector similarity search\n",
    " \n",
    "Execute a pure vector similarity search using the similarity_search() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a similarity search\n",
    "docs = vector_store.similarity_search(query=\"mock draft\", k=1, search_type='similarity')\n",
    "print(docs[0].page_content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "645053d6307d413a1a75681b5ebb6449bb2babba4bcb0bf65a1ddc3dbefb108a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
